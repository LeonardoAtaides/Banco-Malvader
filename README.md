#  Banco Malvader

Sistema bancÃ¡rio completo com chat IA integrado.

---

##  InstalaÃ§Ã£o RÃ¡pida

```bash
# 1. Instalar dependÃªncias
npm install

# 2. Configurar .env
# Crie o .env com suas credenciais MySQL:
DATABASE_URL="mysql://root:senha@localhost:3306/banco_malvader"
OLLAMA_MODEL="tinyllama" #opicional caso queira usar o chat com ia

# 3. Criar banco de dados (escolha UMA opÃ§Ã£o):

Crie o banco de dados sql no local certo que suas credencias do .env indicam

Logo apos:
npx prisma db pull                # Sincronizar schema
npx prisma generate               # Gerar client




# 4. Instalar Ollama (Chat IA - opcional)
winget install Ollama.Ollama   #Ira instalar o setup do ollama no seu computador

# Instale o modelo da ia 
ollama pull tinyllama          # Leve: 637MB (requer ~1-1.5GB RAM)


# 5. Rodar projeto
npm run dev
```

Acesse: http://localhost:3000

---

##  Comandos Ãšteis

```bash
# Banco de dados
mysql -u root -p banco_malvader   # Acessar MySQL
npx prisma db pull                # Atualizar schema.prisma com mudanÃ§as do MySQL
npx prisma generate               # Gerar Prisma Client
npx prisma studio                 # Visualizar dados (GUI)

# Desenvolvimento
npm run dev                  # Servidor desenvolvimento
npm run build               # Build produÃ§Ã£o
npm start                   # Rodar produÃ§Ã£o

# Chat IA (Ollama)
ollama list                      # Ver modelos instalados
ollama pull tinyllama            # Baixar modelo leve (637MB)
ollama pull llama3.2:1b          # Baixar modelo melhor (1.3GB)
ollama run tinyllama "teste"     # Testar modelo
ollama rm [modelo]               # Remover modelo
```

---

##  Estrutura do Banco

O banco estÃ¡ usando **SQL nativo** com:
- âœ… Triggers automÃ¡ticos (saldo, validaÃ§Ãµes)
- âœ… Procedures (alterar senha, calcular score)
- âœ… Functions (gerar nÃºmero conta, Luhn check)
- âœ… Views (resumo contas, movimentaÃ§Ãµes)

**Arquivo**: `database/schema.sql` (contÃ©m tudo)  
**ORM**: Prisma (apenas para queries, nÃ£o para migrations)

---

##  Estrutura

```
â”œâ”€â”€ prisma/
â”‚   â”œâ”€â”€ schema.prisma       # DefiniÃ§Ã£o banco de dados
â”‚   â””â”€â”€ migrations/         # HistÃ³rico de mudanÃ§as
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/               # PÃ¡ginas e rotas Next.js
â”‚   â”‚   â”œâ”€â”€ api/          # API endpoints
â”‚   â”‚   â”œâ”€â”€ Cliente/      # Ãrea do cliente
â”‚   â”‚   â””â”€â”€ Funcionario/  # Ãrea do funcionÃ¡rio
â”‚   â”œâ”€â”€ components/        # Componentes React
â”‚   â”‚   â”œâ”€â”€ ai-chat.tsx   # Chat IA
â”‚   â”‚   â””â”€â”€ navbar.tsx    # NavegaÃ§Ã£o
â”‚   â””â”€â”€ lib/              # UtilitÃ¡rios
â”‚       â”œâ”€â”€ auth.ts       # AutenticaÃ§Ã£o JWT
â”‚       â”œâ”€â”€ prisma.ts     # Cliente Prisma
â”‚       â””â”€â”€ ai/           # Cliente Ollama
â””â”€â”€ public/               # Arquivos estÃ¡ticos
```

---

##  Chat IA

Ver instruÃ§Ãµes completas em: **[AI_SETUP.md](./AI_SETUP.md)**


---

##  Troubleshooting

**Erro: "Table doesn't exist"**
```bash
# Recrie o banco:
mysql -u root -p < database/schema.sql
# Depois atualize o Prisma:
npx prisma db pull
npx prisma generate
```

**Erro: "Database is not in sync"**
```bash
# Se mudou algo no MySQL, puxe as mudanÃ§as:
npx prisma db pull
npx prisma generate
```

**Erro: "Model requires more memory" (Chat IA)**
**SoluÃ§Ã£o 1: Use modelo mais leve**
```bash
ollama pull tinyllama
# Atualizar .env: OLLAMA_MODEL="tinyllama"
```

**SoluÃ§Ã£o 2: Force CPU-only**
```bash
Stop-Process -Name ollama -Force
[System.Environment]::SetEnvironmentVariable('OLLAMA_NUM_GPU', '0', 'User')
Start-Process "ollama"
```

**SoluÃ§Ã£o 3: Libere memÃ³ria**
- Feche Chrome/Edge e outros programas pesados
- Reinicie o computador

**Porta 3000 em uso**
```bash
PORT=3001 npm run dev
```

**Erro: "Cannot find module @prisma/client"**
```bash
npx prisma generate
```

**Porta 3000 em uso**
```bash
PORT=3001 npm run dev
```

---

##  Chat IA

O sistema possui um assistente virtual inteligente que funciona **100% localmente** (sem enviar dados para fora).

### Modelos DisponÃ­veis

| Modelo | Tamanho | RAM | Qualidade | Comando |
|--------|---------|-----|-----------|---------|
| **tinyllama** â­ | 637MB | 1-1.5GB | RazoÃ¡vel | `ollama pull tinyllama` |
| **llama3.2:1b** | 1.3GB | 2-3GB | Boa | `ollama pull llama3.2:1b` |
| **phi3:mini** | 2.2GB | 3-4GB | Excelente | `ollama pull phi3:mini` |

â­ = Recomendado para PCs com pouca RAM

### Como usar

1. **Acesse o Menu do Cliente**: http://localhost:3000/Cliente/Menu
2. **Clique no Ã­cone ğŸ’¬** no canto inferior direito
3. **Digite sua dÃºvida** sobre o banco

### Trocar de modelo

```bash
# Ver modelos instalados
ollama list

# Remover modelo atual
ollama rm tinyllama

# Instalar novo modelo
ollama pull llama3.2:1b

# Atualizar .env
# OLLAMA_MODEL="llama3.2:1b"

# Reiniciar servidor
npm run dev
```

 **Mais detalhes**: Veja [AI_SETUP.md](AI_SETUP.md)

---

##  LicenÃ§a

