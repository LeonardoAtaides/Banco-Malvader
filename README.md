#  Banco Malvader

Sistema banc√°rio completo com chat IA integrado.

---

##  Instala√ß√£o R√°pida

```bash
# 1. Instalar depend√™ncias
npm install

# 2. Configurar .env
cp .env.example .env
# Edite .env com suas credenciais MySQL:
# DATABASE_URL="mysql://root:senha@localhost:3306/banco_malvader"

# 3. Criar banco de dados (escolha UMA op√ß√£o):

# OP√á√ÉO A: Usar SQL direto (recomendado se j√° tem o schema.sql)
mysql -u root -p < database/schema.sql

# OP√á√ÉO B: Usar Prisma migrations
npx prisma migrate deploy
npx prisma generate

# 4. Instalar Ollama (Chat IA - opcional)
winget install Ollama.Ollama
# Escolha o modelo conforme sua RAM:
ollama pull tinyllama          # Leve: 637MB (requer ~1-1.5GB RAM)
# OU
ollama pull llama3.2:1b        # Melhor: 1.3GB (requer ~2-3GB RAM)

# 5. Rodar projeto
npm run dev
```

Acesse: http://localhost:3000

---

##  Comandos √öteis

```bash
# Banco de dados
mysql -u root -p banco_malvader   # Acessar MySQL
npx prisma db pull                # Atualizar schema.prisma com mudan√ßas do MySQL
npx prisma generate               # Gerar Prisma Client
npx prisma studio                 # Visualizar dados (GUI)

# Desenvolvimento
npm run dev                  # Servidor desenvolvimento
npm run build               # Build produ√ß√£o
npm start                   # Rodar produ√ß√£o

# Chat IA (Ollama)
ollama list                      # Ver modelos instalados
ollama pull tinyllama            # Baixar modelo leve (637MB)
ollama pull llama3.2:1b          # Baixar modelo melhor (1.3GB)
ollama run tinyllama "teste"     # Testar modelo
ollama rm [modelo]               # Remover modelo
```

---

##  Estrutura do Banco

O banco est√° usando **SQL nativo** com:
- ‚úÖ Triggers autom√°ticos (saldo, valida√ß√µes)
- ‚úÖ Procedures (alterar senha, calcular score)
- ‚úÖ Functions (gerar n√∫mero conta, Luhn check)
- ‚úÖ Views (resumo contas, movimenta√ß√µes)

**Arquivo**: `database/schema.sql` (cont√©m tudo)  
**ORM**: Prisma (apenas para queries, n√£o para migrations)

---

##  Estrutura

```
‚îú‚îÄ‚îÄ prisma/
‚îÇ   ‚îú‚îÄ‚îÄ schema.prisma       # Defini√ß√£o banco de dados
‚îÇ   ‚îî‚îÄ‚îÄ migrations/         # Hist√≥rico de mudan√ßas
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app/               # P√°ginas e rotas Next.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/          # API endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Cliente/      # √Årea do cliente
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Funcionario/  # √Årea do funcion√°rio
‚îÇ   ‚îú‚îÄ‚îÄ components/        # Componentes React
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ai-chat.tsx   # Chat IA
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ navbar.tsx    # Navega√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ lib/              # Utilit√°rios
‚îÇ       ‚îú‚îÄ‚îÄ auth.ts       # Autentica√ß√£o JWT
‚îÇ       ‚îú‚îÄ‚îÄ prisma.ts     # Cliente Prisma
‚îÇ       ‚îî‚îÄ‚îÄ ai/           # Cliente Ollama
‚îî‚îÄ‚îÄ public/               # Arquivos est√°ticos
```

---

##  Chat IA

Ver instru√ß√µes completas em: **[AI_SETUP.md](./AI_SETUP.md)**

**Requisitos**: 4GB RAM livre  
**Modelo padr√£o**: llama3.2:1b (local, gr√°tis)

---

##  Troubleshooting

**Erro: "Table doesn't exist"**
```bash
# Recrie o banco:
mysql -u root -p < database/schema.sql
# Depois atualize o Prisma:
npx prisma db pull
npx prisma generate
```

**Erro: "Database is not in sync"**
```bash
# Se mudou algo no MySQL, puxe as mudan√ßas:
npx prisma db pull
npx prisma generate
```

**Erro: "Model requires more memory" (Chat IA)**
**Solu√ß√£o 1: Use modelo mais leve**
```bash
ollama pull tinyllama
# Atualizar .env: OLLAMA_MODEL="tinyllama"
```

**Solu√ß√£o 2: Force CPU-only**
```bash
Stop-Process -Name ollama -Force
[System.Environment]::SetEnvironmentVariable('OLLAMA_NUM_GPU', '0', 'User')
Start-Process "ollama"
```

**Solu√ß√£o 3: Libere mem√≥ria**
- Feche Chrome/Edge e outros programas pesados
- Reinicie o computador

**Porta 3000 em uso**
```bash
PORT=3001 npm run dev
```

**Erro: "Cannot find module @prisma/client"**
```bash
npx prisma generate
```

**Porta 3000 em uso**
```bash
PORT=3001 npm run dev
```

---

##  Chat IA

O sistema possui um assistente virtual inteligente que funciona **100% localmente** (sem enviar dados para fora).

### Modelos Dispon√≠veis

| Modelo | Tamanho | RAM | Qualidade | Comando |
|--------|---------|-----|-----------|---------|
| **tinyllama** ‚≠ê | 637MB | 1-1.5GB | Razo√°vel | `ollama pull tinyllama` |
| **llama3.2:1b** | 1.3GB | 2-3GB | Boa | `ollama pull llama3.2:1b` |
| **phi3:mini** | 2.2GB | 3-4GB | Excelente | `ollama pull phi3:mini` |

‚≠ê = Recomendado para PCs com pouca RAM

### Como usar

1. **Acesse o Menu do Cliente**: http://localhost:3000/Cliente/Menu
2. **Clique no √≠cone üí¨** no canto inferior direito
3. **Digite sua d√∫vida** sobre o banco

### Trocar de modelo

```bash
# Ver modelos instalados
ollama list

# Remover modelo atual
ollama rm tinyllama

# Instalar novo modelo
ollama pull llama3.2:1b

# Atualizar .env
# OLLAMA_MODEL="llama3.2:1b"

# Reiniciar servidor
npm run dev
```

 **Mais detalhes**: Veja [AI_SETUP.md](AI_SETUP.md)

---

##  Licen√ßa

